# Pool of credentials to use to crawl (each pool is specified by four properties ending with the same number: integer from 1 to 150)
# Credentials of the pool are used in a round robin way.
#    - for streaming crawlers it is needed to specify only one pool of credentials
#    - for rest crawler, more credential pools are specified, faster is the crawling process
# IMPORTANT: it is possible to specify up to 150 credentials
consumerKey_1=dVyikw316kzOTXO0qwfuxg6kp
consumerSecret_1=iLOqZfykOxyg6EdB266OIE7GwRfUzr2nD1S4jQaW0RellrW43g
token_1=1067069127016280064-kCd7kobkg5DpSwki6Pw9AVWcO2BWWG
tokenSecret_1=Asn6O3yCvQmYgzac05ZrolCxtX0Mv4fXUVqaPRckn5UMZ
####################################################################################
# REST Cralwer of Twitter - by keyword(s)
# Class: org.backingdata.twitter.crawler.rest.TwitterRESTKeywordSearchCrawler
#   - Full path of the txt file to read terms from (one term ID per line)
tweetKeyword.fullPathKeywordList=/home/stefan/twitter-keyword-crawler/keywords.txt
#   - Full path of the output folder to store crawling results 
tweetKeyword.fullOutputDirPath=/home/stefan/twitter-keyword-crawler/out
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetID.outputFormat=tab
#   - If not empty, it is possible specify a language to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetID.languageFilter=



